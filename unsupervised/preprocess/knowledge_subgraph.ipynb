{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "packed-bidder",
   "metadata": {},
   "source": [
    "## Process pretrained node/edge embeddings for knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thermal-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kge.model import KgeModel\n",
    "from kge.util.io import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assigned-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration of dataset wnrr from /home/wuyx/KGE/data/wnrr ...\n",
      "Loaded 11 keys from map relation_ids\n",
      "Setting reciprocal_relations_model.base_model.entity_embedder.dropout to 0., was set to -0.29821809173392233.\n"
     ]
    }
   ],
   "source": [
    "save_folder = '../data/wn18rr_kg'\n",
    "model_path = 'local/experiments/20210329-115948-wn18rr-rescal-train/checkpoint_best.pt'\n",
    "checkpoint = load_checkpoint(model_path)\n",
    "model = KgeModel.create_from(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "literary-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_embedder = model.get_s_embedder()\n",
    "relation_embedder = model.get_p_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vertical-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_statics(dataset):\n",
    "    \"\"\"\n",
    "    Input:  dataset -> [kge.dataset.Dataset]\n",
    "            Dataset for training embeddings(WordNet)\n",
    "    \n",
    "    Output: [None]\n",
    "    \n",
    "    Utils : print statistical information for dataset\n",
    "    \"\"\"\n",
    "    num_entities = dataset.num_entities()\n",
    "    num_relations = dataset.num_relations()\n",
    "    \n",
    "    ent = torch.Tensor([i for i in range(5)]).long()             # subject indexes\n",
    "    rel = torch.Tensor([i for i in range(3)]).long()             # relation indexes\n",
    "    demo_entities = dataset.entity_strings(ent)\n",
    "    demo_relations = dataset.relation_strings(rel)\n",
    "    \n",
    "    print(\"Number of Nodes: {:d}\".format(num_entities))\n",
    "    print(\"Semantics of First 5 Nodes: \", demo_entities)\n",
    "    print()\n",
    "    \n",
    "    print(\"Number of Edge Types: {:d}\".format(num_relations))\n",
    "    print(\"Semantics of First 3 Edge Types: \", demo_relations)\n",
    "    print()\n",
    "    \n",
    "    num_triples = []\n",
    "    for split in [\"train\", \"test\", \"valid\"]:\n",
    "        dataset.load_triples(split)\n",
    "        print(\"Number of Edges in {:s}-set : {:d}\".\\\n",
    "              format(split, dataset._triples[split].size(0)))\n",
    "    print()\n",
    "\n",
    "        \n",
    "def get_vocab(dataset):\n",
    "    \"\"\"\n",
    "    Input:  dataset -> [kge.dataset.Dataset]\n",
    "            Dataset for training embeddings(WordNet)\n",
    "    \n",
    "    Output: vocab -> [Dict]\n",
    "            {word: word_id}\n",
    "    \"\"\"\n",
    "    return {dataset._meta['entity_strings'][i]: i \\\n",
    "             for i in range(dataset.num_entities())}\n",
    "\n",
    "\n",
    "def tokens_to_ids(vocab, batched_data):\n",
    "    \"\"\"\n",
    "    Input:  vocab -> [kge.dataset.Dataset]\n",
    "            Dataset for training embeddings(WordNet)\n",
    "            \n",
    "            batched_data --> [list, np.array]\n",
    "            Batched and tokenized data with shape (Batch_size, Sequence_Length)\n",
    "            \n",
    "    Output: entities_id_list -> [torch.LongTensor]\n",
    "            shape (Batch_size, Sequence_Length)\n",
    "    \"\"\"\n",
    "    def tokens_to_word_ids(tokens, vocab):\n",
    "        return [vocab[word] for word in tokens if word in vocab.keys()]\n",
    "    \n",
    "    entities_id_list = [tokens_to_word_ids(seq, vocab) for seq in batched_data]\n",
    "    return entities_id_list\n",
    "\n",
    "def extract_relations(dataset):\n",
    "    \"\"\"\n",
    "    Input:  dataset -> [kge.dataset.Dataset]\n",
    "            Dataset for training embeddings(WordNet)\n",
    "            \n",
    "    Output: edge_index -> [torch.LongTensor] with shape (2, E)\n",
    "            edge_type  -> [torch.LongTensor] with shape (E) \n",
    "    \"\"\"\n",
    "    all_rels = torch.tensor([])\n",
    "    for split in [\"train\", \"test\", \"valid\"]:\n",
    "        dataset.load_triples(split)\n",
    "        all_rels = torch.cat([all_rels, dataset._triples[split]], dim=0)\n",
    "    \n",
    "    edge_index = all_rels[:, [0, 2]].T.long()\n",
    "    edge_type = all_rels[:, 1].long()\n",
    "    return edge_index, edge_type\n",
    "\n",
    "\n",
    "def get_edge_embs(num_edge_types, egde_embedder):\n",
    "    all_edges = torch.tensor(range(num_edge_types)).long()\n",
    "    edge_embeddings = egde_embedder(all_edges)\n",
    "    return edge_embeddings\n",
    "\n",
    "\n",
    "def get_node_embs(num_node_types, node_embedder):\n",
    "    all_nodes = torch.tensor(range(num_node_types)).long()\n",
    "    node_embeddings = node_embedder(all_nodes)\n",
    "    return node_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blond-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40943 keys from map entity_ids\n",
      "Warning: could not find 439 ids in map entity_strings; filling with None.\n",
      "Loaded 40943 keys from map entity_strings\n",
      "Loaded 11 keys from map relation_strings\n",
      "Number of Nodes: 40943\n",
      "Semantics of First 5 Nodes:  ['land_reform' 'reform' 'cover' 'covering' 'phytology']\n",
      "\n",
      "Number of Edge Types: 11\n",
      "Semantics of First 3 Edge Types:  ['_hypernym' '_derivationally_related_form' '_instance_hypernym']\n",
      "\n",
      "Loaded 86835 train triples\n",
      "Number of Edges in train-set : 86835\n",
      "Loaded 3134 test triples\n",
      "Number of Edges in test-set : 3134\n",
      "Loaded 3034 valid triples\n",
      "Number of Edges in valid-set : 3034\n",
      "\n",
      "the entity id for 'world' is :  27976\n",
      "\n",
      "input test: [[7986, 28531, 4087, 36371], [21866, 34808]]\n",
      "edge_index  torch.Size([2, 93003])\n",
      "edge_type  torch.Size([93003])\n",
      "x  torch.Size([40943, 128])\n",
      "edge_attr  torch.Size([11, 16384])\n"
     ]
    }
   ],
   "source": [
    "# Test above functions\n",
    "\n",
    "dataset = model.dataset\n",
    "dataset_statics(dataset)\n",
    "\n",
    "vocab = get_vocab(dataset)\n",
    "print(\"the entity id for 'world' is : \", vocab[\"world\"])\n",
    "print()\n",
    "\n",
    "entities_id_list = tokens_to_ids(vocab, [[\"hi\", \"i\", \"am\", \"your\", \"friend\", \"good\", \"day\"],\n",
    "                                         [\"hate\", \"terrible\", \"weather\"]])\n",
    "print(\"input test:\", entities_id_list)\n",
    "\n",
    "edge_index, edge_type = extract_relations(dataset)\n",
    "\n",
    "x = get_node_embs(dataset.num_entities(), entity_embedder)\n",
    "edge_attr = get_edge_embs(dataset.num_relations(), relation_embedder)\n",
    "\n",
    "print(\"edge_index \", edge_index.size())\n",
    "print(\"edge_type \", edge_type.size())\n",
    "print(\"x \", x.size())\n",
    "print(\"edge_attr \", edge_attr.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "athletic-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare learned knn graph\n",
    "from torch_cluster.knn import knn_graph\n",
    "knn_edge_index = knn_graph(x, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heard-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pronunciamento' 'chartist' 'passive_resister' 'event_planner'\n",
      " 'paternalism' 'utopian' 'sergei_mikhailovich_eisenstein' 'samuel_goldwyn'\n",
      " 'reform' 'tenderization']\n",
      "['land_reform' 'land_reform' 'land_reform' 'land_reform' 'land_reform'\n",
      " 'land_reform' 'land_reform' 'land_reform' 'reform' 'reform']\n"
     ]
    }
   ],
   "source": [
    "# test knn graph\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "knn_edge_index, _ = remove_self_loops(knn_edge_index)\n",
    "row, col = knn_edge_index[:, :10]\n",
    "row_sent = dataset.entity_strings(row)\n",
    "col_sent = dataset.entity_strings(col)\n",
    "print(row_sent)\n",
    "print(col_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollywood-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed data\n",
    "import os.path as osp\n",
    "\n",
    "torch.save(vocab, osp.join(save_folder, 'vocab.pt'))\n",
    "torch.save(x, osp.join(save_folder, 'wn18rr_x.pt'))\n",
    "torch.save(edge_index, osp.join(save_folder, 'wn18rr_edge_index.pt'))\n",
    "torch.save(knn_edge_index, osp.join(save_folder, 'wn18rr_knn_edge_index.pt'))\n",
    "torch.save(edge_type, osp.join(save_folder, 'wn18rr_edge_type.pt'))\n",
    "torch.save(edge_attr, osp.join(save_folder, 'wn18rr_edge_attr.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sublime-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import networkx as nx\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "\n",
    "save_folder = '../data/wn18rr_kg'\n",
    "vocab = torch.load(osp.join(save_folder, 'vocab.pt'))\n",
    "all_x = torch.load(osp.join(save_folder, 'wn18rr_x.pt'))\n",
    "all_edge_index = torch.load(osp.join(save_folder, 'wn18rr_edge_index.pt'))\n",
    "all_edge_type = torch.load(osp.join(save_folder, 'wn18rr_edge_type.pt'))\n",
    "all_edge_attr = torch.load(osp.join(save_folder, 'wn18rr_edge_attr.pt'))\n",
    "knn_edge_index = torch.load(osp.join(save_folder, 'wn18rr_knn_edge_index.pt'))\n",
    "\n",
    "# simply cat all_edge_index and knn_edge_index, and use the mean edge_attr as knn_edge_attr \n",
    "all_edge_index = torch.cat([all_edge_index, knn_edge_index], dim=1)\n",
    "knn_edge_type = max(all_edge_type) + 1\n",
    "all_edge_type = torch.cat([all_edge_type, torch.ones(knn_edge_index.size(1)).long() * knn_edge_type], dim=0)\n",
    "all_edge_attr = torch.cat([all_edge_attr, all_edge_attr.mean(dim=0).unsqueeze(dim=0)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "responsible-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_x: torch.Size([40943, 128])\n",
      "all_edge_index: torch.Size([2, 420547])\n",
      "all_edge_type: torch.Size([420547])\n",
      "all_edge_attr: torch.Size([12, 16384])\n"
     ]
    }
   ],
   "source": [
    "print('all_x:', all_x.size())\n",
    "print('all_edge_index:', all_edge_index.size())\n",
    "print('all_edge_type:', all_edge_type.size())\n",
    "print('all_edge_attr:', all_edge_attr.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-spank",
   "metadata": {},
   "source": [
    "## Debug for Subgraph extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affected-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "import networkx as nx\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "\n",
    "class Sentence2Graph(object):\n",
    "    \n",
    "    LARGE_NUM = 1e10\n",
    "    \n",
    "    def __init__(self, kg_folder, num_nodes=None):\n",
    "        \"\"\"\n",
    "        all_x          -> [torch.FloatTensor]  shape: (N, node_emb_dim)\n",
    "        all_edge_index -> [torch.LongTensor]   shape: (2, E)\n",
    "        all_edge_type  -> [torch.LongTensor]   shape: (E)\n",
    "        all_edge_attr  -> [torch.FloatTensor]  shape: (n_edge_type, edge_emb_dim)\n",
    "        vocab          -> [Dict] {word: word_id}\n",
    "        \"\"\"\n",
    "        self.vocab = torch.load(osp.join(kg_folder, 'vocab.pt'))\n",
    "        self.all_x = torch.load(osp.join(kg_folder, 'wn18rr_x.pt'))\n",
    "        all_edge_index = torch.load(osp.join(kg_folder, 'wn18rr_edge_index.pt'))\n",
    "        all_edge_type = torch.load(osp.join(kg_folder, 'wn18rr_edge_type.pt'))\n",
    "        all_edge_attr = torch.load(osp.join(kg_folder, 'wn18rr_edge_attr.pt'))\n",
    "        knn_edge_index = torch.load(osp.join(kg_folder, 'wn18rr_knn_edge_index.pt'))\n",
    "\n",
    "        # simply cat all_edge_index and knn_edge_index, and use the mean edge_attr as knn_edge_attr \n",
    "        self.all_edge_index = torch.cat([all_edge_index, knn_edge_index], dim=1)\n",
    "        knn_edge_type = max(all_edge_type) + 1\n",
    "        self.all_edge_type = torch.cat([all_edge_type, torch.ones(knn_edge_index.size(1)).long() * knn_edge_type], dim=0)\n",
    "        self.all_edge_attr = torch.cat([all_edge_attr, all_edge_attr.mean(dim=0).unsqueeze(dim=0)], dim=0)\n",
    "\n",
    "        self.num_nodes = maybe_num_nodes(all_edge_index, num_nodes)\n",
    "        self.G = nx.Graph() # undirected\n",
    "        self.G.add_nodes_from(range(self.num_nodes))\n",
    "        self.G.add_edges_from(list(all_edge_index.cpu().numpy().T))\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_line(line):\n",
    "        '''split given line/phrase into list of words\n",
    "\n",
    "        Input:   line   -> [str]\n",
    "                string representing phrase to be split\n",
    "\n",
    "        Output: strings -> [list]\n",
    "                list of strings, with each string representing a word\n",
    "        '''\n",
    "        return  re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_to_ids(vocab, batched_data):\n",
    "        \"\"\"\n",
    "        Input:  vocab -> [kge.dataset.Dataset]\n",
    "                Dataset for training embeddings(WordNet)\n",
    "\n",
    "                batched_data --> [list, np.array]\n",
    "                Batched and tokenized data with shape (Batch_size, Sequence_Length)\n",
    "\n",
    "        Output: entities_id_list -> [list]\n",
    "                shape (Batch_size, Sequence_Length)\n",
    "        \"\"\"\n",
    "        def tokens_to_word_ids(tokens, vocab):\n",
    "            return list(set([vocab[word] for word in tokens if word in vocab.keys()]))\n",
    "\n",
    "        entities_id_list = [tokens_to_word_ids(seq, vocab) for seq in batched_data]\n",
    "        return entities_id_list\n",
    "\n",
    "    @staticmethod\n",
    "    def subgraph(subset, edge_index, edge_type=None, edge_attr=None, num_nodes=None):\n",
    "        \"\"\"\n",
    "        Returns the induced subgraph of :obj:`(edge_index, edge_attr)`\n",
    "        containing the nodes in :obj:`subset`.\n",
    "\n",
    "        Input:  subset         -> [torch.LongTensor]  \n",
    "                edge_index     -> [torch.LongTensor]   shape: (2, E)\n",
    "                edge_type      -> [torch.LongTensor]   shape: (E)\n",
    "                edge_attr      -> [torch.FloatTensor]  shape: (n_edge_type, edge_emb_dim)\n",
    "\n",
    "        Output: \n",
    "                masked_edge_index    -> [torch.LongTensor]\n",
    "                masked_edge_attr     -> [torch.FloatTensor]\n",
    "        \"\"\"\n",
    "        device = edge_index.device\n",
    "\n",
    "        if isinstance(subset, list) or isinstance(subset, tuple):\n",
    "            subset = torch.tensor(subset, dtype=torch.long)\n",
    "\n",
    "        if subset.dtype == torch.bool or subset.dtype == torch.uint8:\n",
    "            n_mask = subset\n",
    "        else:\n",
    "            num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "            n_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            n_mask[subset] = 1\n",
    "\n",
    "        mask = n_mask[edge_index[0]] & n_mask[edge_index[1]]\n",
    "        masked_edge_index = edge_index[:, mask]\n",
    "\n",
    "        if edge_type is not None:\n",
    "            assert edge_attr is not None\n",
    "            masked_edge_type = edge_type[mask]\n",
    "            masked_edge_attr = edge_attr[masked_edge_type]\n",
    "        else:\n",
    "            masked_edge_attr = None\n",
    "\n",
    "        return masked_edge_index, masked_edge_attr, masked_edge_type\n",
    "    \n",
    "    def __relabel__(self, sub_nodes, edge_index):\n",
    "\n",
    "        sub_nodes = torch.tensor(sub_nodes).long()\n",
    "        row, col = edge_index\n",
    "        # remapping the nodes in the explanatory subgraph to new ids.\n",
    "        node_idx = row.new_full((self.num_nodes,), -1)\n",
    "        node_idx[sub_nodes] = torch.arange(sub_nodes.size(0), device=row.device)\n",
    "        relabeled_edge_index = node_idx[edge_index]\n",
    "        return relabeled_edge_index\n",
    "    \n",
    "    def reduce(self, batched_sentence, device, raw=False):\n",
    "        \"\"\"\n",
    "        Input:  batched_sentence -> [list]\n",
    "\n",
    "                e.g. [[\"good\", \"day\", \"i\", \"am\", \"your\", \"friend\"],\n",
    "                      [\"hate\", \"terrible\", \"weather\"]]\n",
    "                      then set raw = False\n",
    "\n",
    "                or  [[\"good day, i am your friend\"],\n",
    "                      [\"hate terrible weather\"]\n",
    "                    set raw = False\n",
    "\n",
    "        Output:  x, edge_index, edge_attr: information for subgraphs\n",
    "                batch             ->   [torch.LongTensor]  shape: (N)\n",
    "                num_nodes         ->   [torch.LongTensor]  shape: (N_graphs)\n",
    "                num_edges         ->   [torch.LongTensor]  shape: (N_graphs)\n",
    "                flat_entities_id  ->   [list]              \n",
    "                edge_type         ->   [torch.LongTensor]  shape: (E)\n",
    "        \"\"\"\n",
    "        if raw:\n",
    "            batched_sentence = [self.split_line(sentence.lower()) for sentence in batched_sentence]\n",
    "        entities_id = self.tokens_to_ids(self.vocab, batched_sentence)\n",
    "\n",
    "        num_nodes = torch.tensor([len(entities) for entities in entities_id]).long()\n",
    "        batch = torch.tensor([i for i in range(len(num_nodes)) for _ in range(num_nodes[i])]).long()\n",
    "        cum_nodes = torch.cat([batch.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]]).long()\n",
    "        \n",
    "        def extract_subgraph(entities):\n",
    "            node_idx = torch.unique(torch.tensor(entities).long())\n",
    "            masked_edge_index, masked_edge_attr, masked_edge_type = self.subgraph(node_idx, self.all_edge_index, self.all_edge_type, self.all_edge_attr)\n",
    "            return masked_edge_index, masked_edge_attr, masked_edge_type\n",
    "        \n",
    "        num_edges = []\n",
    "        x = torch.tensor([])\n",
    "        edge_index = torch.tensor([[], []])\n",
    "        edge_attr = torch.tensor([])\n",
    "        edge_type = torch.tensor([])\n",
    "        \n",
    "        for i, entities in enumerate(entities_id):\n",
    "            x = torch.cat([x, self.all_x[entities]], dim=0)\n",
    "            masked_edge_index, masked_edge_attr, masked_edge_type = extract_subgraph(entities)\n",
    "            masked_edge_index = self.__relabel__(entities, masked_edge_index) + cum_nodes[i]\n",
    "            \n",
    "            edge_index = torch.cat([edge_index, masked_edge_index], dim=1)\n",
    "            edge_type = torch.cat([edge_type, masked_edge_type], dim=0)\n",
    "            edge_attr = torch.cat([edge_attr, masked_edge_attr], dim=0)\n",
    "            num_edges.append(masked_edge_index.size(1))\n",
    "            \n",
    "        num_edges = torch.tensor(num_edges).long()\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.long().to(device)\n",
    "        edge_type = edge_type.long().to(device)\n",
    "        edge_attr = edge_attr.to(device)\n",
    "        num_nodes = num_nodes.to(device)\n",
    "        num_edges = num_edges.to(device)\n",
    "        \n",
    "        flat_entities_id = []\n",
    "        for entities in entities_id:\n",
    "            flat_entities_id.extend(entities)\n",
    "        flat_entities_id = torch.tensor(flat_entities_id).long().to(device)\n",
    "        \n",
    "        assert x.size(0) == flat_entities_id.size(0)\n",
    "        assert x.size(0) == batch.size(0)\n",
    "        \n",
    "        assert edge_index.size(1) == edge_attr.size(0)\n",
    "        assert edge_index.size(1) == edge_type.size(0)\n",
    "        assert len(num_nodes) == len(num_edges)\n",
    "        \n",
    "        return x, edge_index, edge_attr, batch, num_nodes, num_edges, flat_entities_id, edge_type\n",
    "    \n",
    "    def reduce_connected(self, batched_sentence, device, raw=False):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        Input:  batched_sentence -> [list]\n",
    "\n",
    "                e.g. [[\"good\", \"day\", \"i\", \"am\", \"your\", \"friend\"],\n",
    "                      [\"hate\", \"terrible\", \"weather\"]]\n",
    "                      then set raw=True\n",
    "\n",
    "                or  [[\"good day, i am your friend\"],\n",
    "                      [\"hate terrible weather\"]\n",
    "                    set raw = False\n",
    "\n",
    "        Output:  x, edge_index, edge_attr: information for subgraphs\n",
    "                batch             ->   [torch.LongTensor]  shape: (N)\n",
    "                num_nodes         ->   [torch.LongTensor]  shape: (N_graphs)\n",
    "                num_edges         ->   [torch.LongTensor]  shape: (N_graphs)\n",
    "                flat_entities_id  ->   [list]              \n",
    "                edge_type         ->   [torch.LongTensor]  shape: (E)\n",
    "        \"\"\"\n",
    "        # 1. prerpocess the input sentences into lists of entities\n",
    "        if raw:\n",
    "            batched_sentence = [self.split_line(sentence.lower()) for sentence in batched_sentence]\n",
    "        entities_id = self.tokens_to_ids(self.vocab, batched_sentence)\n",
    "        num_edges = []\n",
    "        num_nodes = []\n",
    "        cum_nodes = [0]\n",
    "        flat_entities_id = []\n",
    "        x = torch.tensor([]).to(device)\n",
    "        edge_index = torch.tensor([[], []]).long().to(device)\n",
    "        edge_attr = torch.tensor([]).to(device)\n",
    "        edge_type = torch.tensor([]).long().to(device)\n",
    "        for subset in entities_id:\n",
    "            # 2. for each node subset, we calculate the pair-wise distance\n",
    "            # ... and get the minimum spanning tree whose nodes contains subset \n",
    "            n =  len(subset)\n",
    "            flag = 1\n",
    "            if n < 2:\n",
    "                num_nodes.append(n)\n",
    "                num_edges.append(0)\n",
    "                cum_nodes.append(cum_nodes[-1] + num_nodes[-1]) \n",
    "                x = torch.cat([x, self.all_x[subset].to(device)], dim=0)\n",
    "                flat_entities_id.extend(subset)\n",
    "                continue\n",
    "                \n",
    "            g = nx.DiGraph()\n",
    "            adj = torch.ones([n, n]) * self.LARGE_NUM\n",
    "            paths = {i:{} for i in range(n)}\n",
    "            g.add_nodes_from(subset)\n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    try:\n",
    "                        path_ij = nx.shortest_path(self.G, source=subset[i], target=subset[j])\n",
    "                        g.add_weighted_edges_from([(subset[i], subset[j], len(path_ij))])\n",
    "                        g.add_weighted_edges_from([(subset[j], subset[i], len(path_ij))])\n",
    "                        paths[i][j] = path_ij\n",
    "                    except:\n",
    "                        flag = 0\n",
    "                        break\n",
    "                if flag ==0 :\n",
    "                    break\n",
    "            if flag ==0 :\n",
    "                num_nodes.append(n)\n",
    "                num_edges.append(0)\n",
    "                cum_nodes.append(cum_nodes[-1] + num_nodes[-1]) \n",
    "                x = torch.cat([x, self.all_x[subset].to(device)], dim=0)\n",
    "                flat_entities_id.extend(subset)\n",
    "                continue\n",
    "            sg = nx.minimum_spanning_arborescence(g)\n",
    "            sg_edges = list(sg.edges)\n",
    "            \n",
    "            # 3. collect the paths(each path representes an ego edge in the spanning tree) \n",
    "            # ... into one graph\n",
    "            sub_nodes = []\n",
    "            return_edge_index = []\n",
    "            return_edge_type = []\n",
    "            row, col = self.all_edge_index\n",
    "            for e in sg_edges:\n",
    "                _i = subset.index(e[0]); _j = subset.index(e[1])\n",
    "                i = min(_i, _j); j = max(_i, _j)\n",
    "                p = paths[i][j]\n",
    "                sub_nodes.extend(p)\n",
    "                for k in range(len(p)-1):\n",
    "                    return_edge_index.append([p[k], p[k+1]])\n",
    "                    mask = (row == p[k]) * (col == p[k+1])\n",
    "                    if mask.sum() > 0:\n",
    "                        return_edge_type.append(self.all_edge_type[torch.nonzero(mask).view(-1)[0]])\n",
    "                    else:\n",
    "                        mask = (row == p[k+1]) * (col == p[k])\n",
    "                        return_edge_type.append(self.all_edge_type[torch.nonzero(mask).view(-1)[0]])\n",
    "                    \n",
    "            # 4. aggregate the subgraph into batch\n",
    "            sub_nodes = torch.tensor(sub_nodes).long().unique().to(device)\n",
    "            num_nodes.append(sub_nodes.size(0))\n",
    "            return_x = self.all_x[sub_nodes].to(device)\n",
    "            \n",
    "            return_edge_index = torch.tensor(return_edge_index).long().T.to(device)\n",
    "            return_edge_index = self.__relabel__(sub_nodes, return_edge_index) + cum_nodes[-1]\n",
    "            \n",
    "            return_edge_type = torch.tensor(return_edge_type).to(device)\n",
    "            return_edge_attr = self.all_edge_attr[return_edge_type].to(device)\n",
    "            \n",
    "            cum_nodes.append(cum_nodes[-1] + num_nodes[-1])\n",
    "            num_edges.append(return_edge_index.size(1))\n",
    "            \n",
    "            x = torch.cat([x, return_x], dim=0)\n",
    "            edge_index = torch.cat([edge_index, return_edge_index], dim=1)\n",
    "            edge_attr = torch.cat([edge_attr, return_edge_attr], dim=0)\n",
    "            edge_type = torch.cat([edge_type, return_edge_type], dim=0)\n",
    "            flat_entities_id.extend(sub_nodes.tolist())\n",
    "            \n",
    "        num_nodes = torch.tensor(num_nodes).long()\n",
    "        num_edges = torch.tensor(num_edges).long()\n",
    "        num_nodes = num_nodes.to(device)\n",
    "        num_edges = num_edges.to(device)\n",
    "        flat_entities_id = torch.tensor(flat_entities_id).long().to(device)\n",
    "        batch = torch.tensor([i for i in range(len(num_nodes)) for _ in range(num_nodes[i])]).long().to(device)\n",
    "        \n",
    "        \n",
    "        assert x.size(0) == flat_entities_id.size(0)\n",
    "        assert x.size(0) == batch.size(0)\n",
    "        \n",
    "        assert edge_index.size(1) == edge_attr.size(0)\n",
    "        assert edge_index.size(1) == edge_type.size(0)\n",
    "        assert len(num_nodes) == len(num_edges)\n",
    "        \n",
    "        return x, edge_index, edge_attr, batch, num_nodes, num_edges, flat_entities_id, edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impossible-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['you'], ['you', 'are'], ['you', 'are', 'a'], ['you', 'are', 'a', 'kind'], ['you', 'are', 'a', 'kind', 'man'], ['what'], ['what', 'a'], ['what', 'a', 'beautiful'], ['what', 'a', 'beautiful', 'day'], ['what', 'a', 'beautiful', 'day', '!']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def batch_seq(sentences, intervel=1):\n",
    "    # assume the lengthes are the same for the sentences\n",
    "    sentences = np.array(sentences, dtype=np.str)\n",
    "    l = sentences.shape[1]\n",
    "    seq = []\n",
    "    for i in range(1, l+1):\n",
    "        seq.extend([sentences[:, :i].tolist()])\n",
    "    seq = np.array(seq).T\n",
    "    seq = seq.tolist()\n",
    "    \n",
    "    res_seq = []\n",
    "    for subseq in seq:\n",
    "        res_seq.extend(subseq)\n",
    "    return res_seq\n",
    "seq = batch_seq([['you', 'are', 'a', 'kind', 'man'], ['what', 'a', 'beautiful', 'day', \"!\"]])\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "administrative-bolivia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentence2graph = Sentence2Graph(kg_folder='wn18rr_kg')\n",
    "x, edge_index, edge_attr, batch, num_nodes, num_edges, entities_id, edge_type = sentence2graph.reduce_connected(batched_sentence=seq, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collaborative-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 16384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-freedom",
   "metadata": {},
   "source": [
    "### Toy Example  (without SubgraphFinder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "raising-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([7, 128])\n",
      "edge_index: torch.Size([2, 2])\n",
      "edge_attr: torch.Size([2, 16384])\n",
      "batch: torch.Size([7])\n",
      "num subgraphs: 3\n",
      "num nodes: tensor([3, 2, 2], device='cuda:0')\n",
      "num edges: tensor([0, 0, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batched_sentence = [[]]\n",
    "x, edge_index, edge_attr, batch, num_nodes, num_edges, entities_id, edge_type = sentence2graph.reduce(batched_sentence, device=device)\n",
    "print('x:', x.size())\n",
    "print('edge_index:', edge_index.size())\n",
    "print('edge_attr:', edge_attr.size())\n",
    "print('batch:', batch.size())\n",
    "print('num subgraphs:', len(torch.unique(batch)))\n",
    "print('num nodes:', num_nodes)\n",
    "print('num edges:', num_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-symphony",
   "metadata": {},
   "source": [
    "#### check the returned graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fifteen-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration of dataset wnrr from /home/wuyx/MetaKG/KGE/data/wnrr ...\n",
      "Loaded 11 keys from map relation_ids\n",
      "Setting reciprocal_relations_model.base_model.entity_embedder.dropout to 0., was set to -0.29821809173392233.\n",
      "Loaded 40943 keys from map entity_ids\n",
      "Warning: could not find 439 ids in map entity_strings; filling with None.\n",
      "Loaded 40943 keys from map entity_strings\n",
      "['friend' 'day' 'good' 'weather' 'hate' 'phytology' 'botanize']\n",
      "Loaded 11 keys from map relation_strings\n",
      "phytology-->_derivationally_related_form-->botanize\n",
      "botanize-->_derivationally_related_form-->phytology\n"
     ]
    }
   ],
   "source": [
    "from kge.model import KgeModel\n",
    "from kge.util.io import load_checkpoint\n",
    "\n",
    "save_folder = 'wn18rr_kg'\n",
    "model_path = 'local/experiments/20210329-115948-wn18rr-rescal-train/checkpoint_best.pt'\n",
    "checkpoint = load_checkpoint(model_path)\n",
    "model = KgeModel.create_from(checkpoint)\n",
    "\n",
    "dataset = model.dataset\n",
    "print(dataset.entity_strings(entities_id))\n",
    "\n",
    "for i in range(edge_index.size(1)):\n",
    "    print(\"%s-->%s-->%s\" % (dataset.entity_strings(entities_id[edge_index[0, i]]), \n",
    "                            dataset.relation_strings(edge_type[i]), \n",
    "                            dataset.entity_strings(entities_id[edge_index[1, i]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-trainer",
   "metadata": {},
   "source": [
    "### Toy Example  (with SubgraphFinder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "circular-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40943\n",
      "x: torch.Size([6, 128])\n",
      "edge_index: torch.Size([2, 5])\n",
      "edge_attr: torch.Size([5, 16384])\n",
      "batch: torch.Size([6])\n",
      "num subgraphs: 1\n",
      "num nodes: tensor([6], device='cuda:0')\n",
      "num edges: tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batched_sentence = [\"Thank you for the love and encourgement, sweetheart\"]\n",
    "                    # [[\"good\", \"day\", \"i\", \"am\", \"your\", \"friend\"],\n",
    "                    # [\"hate\", \"terrible\", \"weather\"],\n",
    "                    # [\"phytology\", \"botanize\"]]\n",
    "print(sentence2graph.num_nodes)\n",
    "x, edge_index, edge_attr, batch, num_nodes, num_edges, entities_id, edge_type = sentence2graph.reduce_connected(batched_sentence, device=device, raw=True)\n",
    "print('x:', x.size())\n",
    "print('edge_index:', edge_index.size())\n",
    "print('edge_attr:', edge_attr.size())\n",
    "print('batch:', batch.size())\n",
    "print('num subgraphs:', len(torch.unique(batch)))\n",
    "print('num nodes:', num_nodes)\n",
    "print('num edges:', num_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-warren",
   "metadata": {},
   "source": [
    "#### see if the reduced connected graph makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "polar-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woman' 'soul' 'lover' 'female_person' 'love' 'sweetheart']\n",
      "love-->_derivationally_related_form-->lover\n",
      "lover-->_hypernym-->soul\n",
      "soul-->_hypernym-->female_person\n",
      "female_person-->_hypernym-->woman\n",
      "woman-->_hypernym-->sweetheart\n"
     ]
    }
   ],
   "source": [
    "print(dataset.entity_strings(entities_id))\n",
    "\n",
    "for i in range(edge_index.size(1)):\n",
    "    \n",
    "    _type = 'knn-link' if edge_type[i] > 10 else dataset.relation_strings(edge_type[i])\n",
    "    print(\"%s-->%s-->%s\" % (dataset.entity_strings(entities_id[edge_index[0, i]]), \n",
    "                            _type, \n",
    "                            dataset.entity_strings(entities_id[edge_index[1, i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "julian-screw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['_hypernym', '_derivationally_related_form', '_instance_hypernym',\n",
       "       '_also_see', '_member_meronym', '_synset_domain_topic_of',\n",
       "       '_has_part', '_member_of_domain_usage', '_member_of_domain_region',\n",
       "       '_verb_group'], dtype='<U28')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.relation_strings(torch.LongTensor([i for i in range(10)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
